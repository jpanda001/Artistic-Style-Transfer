{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Style Transfer Model Prototype.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpanda001/Artistic-Style-Transfer/blob/master/Style_Transfer_Model_Prototype.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOCs8WSIAkTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision.models as models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBOzOUCMUSRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg19 = models.vgg19(pretrained=True).features.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAsrCjBlXwHV",
        "colab_type": "code",
        "outputId": "715e1658-7559-4495-9b60-e4de29d90c7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(vgg19, input_size=(3, 256, 256))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 256, 256]           1,792\n",
            "              ReLU-2         [-1, 64, 256, 256]               0\n",
            "            Conv2d-3         [-1, 64, 256, 256]          36,928\n",
            "              ReLU-4         [-1, 64, 256, 256]               0\n",
            "         MaxPool2d-5         [-1, 64, 128, 128]               0\n",
            "            Conv2d-6        [-1, 128, 128, 128]          73,856\n",
            "              ReLU-7        [-1, 128, 128, 128]               0\n",
            "            Conv2d-8        [-1, 128, 128, 128]         147,584\n",
            "              ReLU-9        [-1, 128, 128, 128]               0\n",
            "        MaxPool2d-10          [-1, 128, 64, 64]               0\n",
            "           Conv2d-11          [-1, 256, 64, 64]         295,168\n",
            "             ReLU-12          [-1, 256, 64, 64]               0\n",
            "           Conv2d-13          [-1, 256, 64, 64]         590,080\n",
            "             ReLU-14          [-1, 256, 64, 64]               0\n",
            "           Conv2d-15          [-1, 256, 64, 64]         590,080\n",
            "             ReLU-16          [-1, 256, 64, 64]               0\n",
            "           Conv2d-17          [-1, 256, 64, 64]         590,080\n",
            "             ReLU-18          [-1, 256, 64, 64]               0\n",
            "        MaxPool2d-19          [-1, 256, 32, 32]               0\n",
            "           Conv2d-20          [-1, 512, 32, 32]       1,180,160\n",
            "             ReLU-21          [-1, 512, 32, 32]               0\n",
            "           Conv2d-22          [-1, 512, 32, 32]       2,359,808\n",
            "             ReLU-23          [-1, 512, 32, 32]               0\n",
            "           Conv2d-24          [-1, 512, 32, 32]       2,359,808\n",
            "             ReLU-25          [-1, 512, 32, 32]               0\n",
            "           Conv2d-26          [-1, 512, 32, 32]       2,359,808\n",
            "             ReLU-27          [-1, 512, 32, 32]               0\n",
            "        MaxPool2d-28          [-1, 512, 16, 16]               0\n",
            "           Conv2d-29          [-1, 512, 16, 16]       2,359,808\n",
            "             ReLU-30          [-1, 512, 16, 16]               0\n",
            "           Conv2d-31          [-1, 512, 16, 16]       2,359,808\n",
            "             ReLU-32          [-1, 512, 16, 16]               0\n",
            "           Conv2d-33          [-1, 512, 16, 16]       2,359,808\n",
            "             ReLU-34          [-1, 512, 16, 16]               0\n",
            "           Conv2d-35          [-1, 512, 16, 16]       2,359,808\n",
            "             ReLU-36          [-1, 512, 16, 16]               0\n",
            "        MaxPool2d-37            [-1, 512, 8, 8]               0\n",
            "================================================================\n",
            "Total params: 20,024,384\n",
            "Trainable params: 20,024,384\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 311.25\n",
            "Params size (MB): 76.39\n",
            "Estimated Total Size (MB): 388.39\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nClw_gKfQkyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## I dont think we need this at all\n",
        "class Vgg(nn.Module): #\n",
        "  def __init__(self,num_hidden):\n",
        "    super(Vgg,self).__init__()                    \n",
        "    self.name = \"Vgg\"\n",
        "    self.fc1 = nn.Linear(1000,100)  \n",
        "    self.fc2 = nn.Linear(100,10)\n",
        "    self.fc3 = nn.Linear(10,2)       #output size = ?                              \n",
        "    self.num_hidden = num_hidden\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x))                               #apply relu activation function to make sure it's not linear relationship, output=100                         \n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.relu(self.fc(x)) \n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKnP3z7ZZrB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder = nn.Sequential( \n",
        "            nn.Conv2d(3, 16, 3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 7)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64, 32, 7),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98f0dy3ibAXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Transformer, self).__init__()\n",
        "#conv layers\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=9, stride=1)      #How to implement batch normalization?\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=5, stride=1)\n",
        "        self.pool = nn.maxpool2d(2,2)\n",
        "# Res layers\n",
        "  \n",
        "  #How to build residual Layers?\n",
        "\n",
        "# deconv Layers\n",
        "        self.de_conv1 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=1)\n",
        "        self.de_conv2 = nn.ConvTranspose2d(64, 32, kernel_size=5, stride=1)\n",
        "        self.de_conv3 = nn.ConvTranspose2d(32, 3, kernel_size=5, stride=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "      # x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "      #  x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "      #  x = self.pool(x)  #28*28\n",
        "      # x = self.res(x)  #?\n",
        "        x = F.relu(self.de_conv1(x))\n",
        "        x = F.relu(self.de_conv2(x))\n",
        "        x = F.de_conv3(x)\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyJrnScIcLEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training Network\n",
        "def train(generator, discriminator, lr=0.001, num_epochs=5, style_weight = 100, content_weight = 1):\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    #d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
        "    g_optimizer = torch.optim.Adam(generator.parameters(), lr=lr)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(mnist_data, batch_size=100, shuffle=True)\n",
        "\n",
        "    num_test_samples = 16\n",
        "    test_noise = torch.randn(num_test_samples, 100)\n",
        "\n",
        "    content_layers = ['conv_4']\n",
        "    style_layers = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # label that we are using both models \n",
        "        generator.train()\n",
        "        discriminator.train()\n",
        "\n",
        "\n",
        "        for n, (images, _) in enumerate(train_loader):\n",
        "          \n",
        "            for layers in vgg19.features:\n",
        "              if isinstance(layers,conv_2d):\n",
        "                i += 1\n",
        "                name = 'conv_{}'.format(i)\n",
        "                            \n",
        "              if name in content_layers:\n",
        "                noise = torch.randn(images.size(0), 100)\n",
        "                transformed_images = generator(noise)\n",
        "                transformed_content = vgg19(transformed_images)\n",
        "                content_content = vgg19(content_image)\n",
        "                content_loss = F.mse_loss(transformed_content, content_content)\n",
        "              \n",
        "              if name in style_layers:\n",
        "                noise = torch.randn(images.size(0), 100)\n",
        "                transformed_images = generator(noise)\n",
        "                transformed_style = vgg19(transformed_images)\n",
        "                style_style = vgg19(style_image)\n",
        "                style_loss = F.mse_loss(transformed_style, style_style)\n",
        "              \n",
        "              g_loss = style_weight*style_loss + content_weight*content_loss\n",
        "              g_loss.backward()\n",
        "              g_optimizer.step()\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}